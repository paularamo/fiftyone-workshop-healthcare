{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè• Visual AI in Healthcare with FiftyOne ‚Äì VFMs and C-RADIO for ARCADE Dataset\n",
    "**Exploring visual representations in medical datasets with VLMs and embedding search**\n",
    "\n",
    "This notebook is part of the **‚ÄúVisual AI in Healthcare with FiftyOne‚Äù** workshop. Through hands-on examples, we explore how to analyze medical datasets using Visual Foundation Models (VFMs) and embedding-based search to select representative samples for downstream tasks like fine-tuning object detection models.\n",
    "\n",
    "üî¨ **What you‚Äôll learn in this notebook:**\n",
    "\n",
    "- How to **load the ARCADE dataset** from Hugging Face using FiftyOne utilities  \n",
    "- How to **extract embeddings** using NVIDIA‚Äôs **C-RADIO** embedding model  \n",
    "- How to **perform similarity and uniqueness queries** with FiftyOne Brain  \n",
    "- How to **select the most unique and representative images** for training  \n",
    "- How to **visualize the filtered results** interactively in the FiftyOne App  \n",
    "- How to **export curated datasets** and share them on Hugging Face  \n",
    "\n",
    "üìö **Part of the notebook series:**\n",
    "1. `01_load_arcade_dataset.ipynb` ‚Äì Load and visualize the ARCADE dataset.  \n",
    "2. `02_load_deeplesion_balanced.ipynb` ‚Äì Curate and balance the DeepLesion dataset.  \n",
    "3. `03_vlms_analysis_arcade.ipynb` ‚Äì Use VFMs like NVLabs_CRADIOV3 in dataset undersatnding for ARCADE. \n",
    "4. `04_finetune_yolo8_stenosis.ipynb` ‚Äì Train and integrate YOLOv8 for stenosis detection.  \n",
    "5. `05_medsam2_ct_scan.ipynb` ‚Äì Run MedSAM2 on CT scans for segmentation.  \n",
    "6. `06_nvidia_vista_segmentation.ipynb` ‚Äì Explore NVIDIA-VISTA-3D.  \n",
    "7. `07_medgemma_vqa.ipynb` ‚Äì Perform visual question answering and classification with MedGemma.\n",
    "\n",
    "All notebooks are standalone but are best experienced sequentially.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Load the ARCADE dataset from Hugging Face Hub\n",
    "\n",
    "We begin by importing the ARCADE dataset, a CT angiography dataset curated for stenosis detection, directly from the Hugging Face Hub using FiftyOne's `load_from_hub()` utility.\n",
    "\n",
    "Before loading, we check if a dataset with the same name already exists in your local FiftyOne environment. If it does, we delete it to ensure a clean workspace for this notebook.\n",
    "\n",
    "Key points:\n",
    "\n",
    "- Uses `Voxel51/ARCADE_FO` as the dataset name (FiftyOne handles this internally without slashes)\n",
    "- Ensures no name conflict by deleting any previously loaded dataset with the same name\n",
    "- Downloads the `train` split from Hugging Face for interactive querying and filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "# Name used internally by FiftyOne (it does not use slashes like 'Voxel51/BTCV-...')\n",
    "dataset_name = \"Voxel51/ARCADE_FO\"\n",
    "\n",
    "# Delete the dataset if it exists\n",
    "if fo.dataset_exists(dataset_name):\n",
    "    fo.delete_dataset(dataset_name)\n",
    "    print(f\"Deleted existing dataset: {dataset_name}\")\n",
    "else:\n",
    "    print(f\"No dataset found with name: {dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "from fiftyone.utils.huggingface import load_from_hub\n",
    "\n",
    "dataset = load_from_hub(\n",
    "    \"Voxel51/ARCADE_FO\", split=\"train\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîå Registering a Remotely-Sourced Zoo Model: C-RADIOv3\n",
    "\n",
    "FiftyOne allows you to register and use **remotely-sourced zoo models**, meaning model definitions and configurations can be hosted outside of the FiftyOne codebase ‚Äî for example, in GitHub repositories or public URLs.\n",
    "\n",
    "This capability enables developers and researchers to contribute and share models that are easily accessible and fully compatible with FiftyOne‚Äôs Zoo API.\n",
    "\n",
    "### üí° What is a Remotely-Sourced Zoo Model?\n",
    "\n",
    "Instead of being built-in, a remotely-sourced model is hosted externally but can be registered and used just like native FiftyOne zoo models. You only need to provide a URL to the model's repository or archive.\n",
    "\n",
    "üìå You can register a model source via:\n",
    "- GitHub repository (e.g. `https://github.com/<user>/<repo>`)\n",
    "- GitHub refs (`/tree/<branch>` or `/commit/<sha>`)\n",
    "- Archive URLs (e.g. `.zip`, `.tar.gz`)\n",
    "\n",
    "---\n",
    "\n",
    "### ü§ñ C-RADIOv3 Models\n",
    "\n",
    "In this notebook, we are using a registered model, the [C-RADIOv3 model family](https://github.com/harpreetsahota204/NVLabs_CRADIOV3), created by Harpreet Sahota. These models are designed for **semantic image embeddings** using Vision Transformers and support a variety of architectures and trade-offs between speed and performance.\n",
    "\n",
    "| Model Name              | Description        | Architecture | Patch Size | Best For                          |\n",
    "|-------------------------|--------------------|--------------|------------|-----------------------------------|\n",
    "| `nv_labs/c-radio_v3-b`  | C-RADIOv3-B        | ViT-B/16     | 16√ó16      | Fast inference, moderate accuracy |\n",
    "| `nv_labs/c-radio_v3-l`  | C-RADIOv3-L        | ViT-L/16     | 16√ó16      | Balanced performance              |\n",
    "| `nv_labs/c-radio_v3-h`  | C-RADIOv3-H        | ViT-H/16     | 16√ó16      | High accuracy (recommended)       |\n",
    "| `nv_labs/c-radio_v3-g`  | C-RADIOv3-G        | ViT-H/14     | 14√ó14      | Maximum performance               |\n",
    "\n",
    "Once registered, these models can be directly used via FiftyOne‚Äôs `load_zoo_model()` API for embedding generation, visualization, and semantic search.\n",
    "\n",
    "We‚Äôll explore those capabilities in the next steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you register the zoo model source:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.zoo as foz\n",
    "\n",
    "foz.register_zoo_model_source(\n",
    "    \"https://github.com/harpreetsahota204/NVLabs_CRADIOV3\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, instantiate the model. Let's start with computing embeddings.\n",
    "\n",
    "Note: Refer to the [README](https://github.com/harpreetsahota204/NVLabs_CRADIOV3/blob/main/README.md) for available model checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radio_embeddings_model = foz.load_zoo_model(\n",
    "    \"nv_labs/c-radio_v3-h\",\n",
    "    feature_format=\"NCHW\", # you can also pass NLC here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compute embeddings as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.compute_embeddings(\n",
    "    model=radio_embeddings_model,\n",
    "    embeddings_field=\"radio_embeddings\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have your embeddings, you can compute the visualization to visualize in the FiftyOne App:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.brain as fob\n",
    "\n",
    " \n",
    "results = fob.compute_visualization(\n",
    "    dataset,\n",
    "    model=radio_embeddings_model,\n",
    "    method=\"umap\",  # \"umap\", \"tsne\", \"pca\", etc\n",
    "    brain_key=\"radio_viz\",\n",
    "    embeddings=\"radio_embeddings\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.reload()\n",
    "dataset.persistent = True\n",
    "\n",
    "# Make sure this is run after all processing\n",
    "session = fo.launch_app(dataset, port=5151, auto=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also build a similarity index over the embeddings to find similar samples in your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.brain as fob\n",
    "\n",
    "results = fob.compute_similarity(\n",
    "    dataset,\n",
    "    model=radio_embeddings_model,\n",
    "    backend=\"sklearn\",  # \"sklearn\", \"qdrant\", \"redis\", etc\n",
    "    brain_key=\"radio_sim\",\n",
    "    embeddings_field=\"radio_embeddings\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your computed embeddings you can also perform other embeddings based workflows such as computing uniqueness values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.brain as fob\n",
    "\n",
    "fob.compute_uniqueness(\n",
    "    dataset,\n",
    "    model=radio_embeddings_model,\n",
    "    uniqueness_field=\"radio_uniqueness\",\n",
    "    similarity_index=\"radio_sim\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also compute representativeness scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.brain as fob\n",
    "\n",
    "fob.compute_representativeness(\n",
    "    dataset,\n",
    "    model=radio_embeddings_model,\n",
    "    representativeness_field=\"radio_representativeness\",\n",
    "    similarity_index=\"radio_sim\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 most unique\n",
    "unique_view = dataset.sort_by(\"radio_uniqueness\", reverse=True).limit(20)\n",
    "unique_view.tag_samples(\"top_unique\")\n",
    "\n",
    "# Top 20 most representative\n",
    "rep_view = dataset.sort_by(\"radio_representativeness\", reverse=True).limit(20)\n",
    "rep_view.tag_samples(\"top_representative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.reload()\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Spatial Features\n",
    "\n",
    "You can also compute spatial features. To use this feature you need to set `output_type=\"spatial\"`, additionally spatial features only supports `feature_format=\"NCHW\"`.\n",
    "\n",
    "You can choose to do some Gaussian smoothing if you'd like, just set `apply_smoothing=True` and choose a value for `smoothing_sigma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radio_spatial_model = foz.load_zoo_model(\n",
    "    \"nv_labs/c-radio_v3-h\",\n",
    "    output_type=\"spatial\",\n",
    "    apply_smoothing=True, # if you want smoothing\n",
    "    smoothing_sigma=0.8, # how much smoothing you want to apply\n",
    "    feature_format=\"NCHW\" #this is the required for the heatmap\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we are using the `apply_model` method here, as we are not computing 1D embeddings like above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.apply_model(\n",
    "    radio_spatial_model,\n",
    "    \"radio_spatial_features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view your results in the app like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.launch_app(dataset, port=5151, auto=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.persistent=True\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a subset for finetuning:\n",
    "\n",
    "# 1. Filter samples where task == \"stenosis\"\n",
    "stenosis_view = dataset.match({\"task\": \"stenosis\"})\n",
    "\n",
    "# 2. Sort by both uniqueness and representativeness\n",
    "# Normalize values for fairness in ranking\n",
    "import numpy as np\n",
    "\n",
    "uniqueness_values = [s[\"radio_uniqueness\"] for s in stenosis_view if s[\"radio_uniqueness\"] is not None]\n",
    "representativeness_values = [s[\"radio_representativeness\"] for s in stenosis_view if s[\"radio_representativeness\"] is not None]\n",
    "\n",
    "# Min-max normalization\n",
    "min_u, max_u = min(uniqueness_values), max(uniqueness_values)\n",
    "min_r, max_r = min(representativeness_values), max(representativeness_values)\n",
    "\n",
    "def normalize(val, min_val, max_val):\n",
    "    return (val - min_val) / (max_val - min_val + 1e-8)\n",
    "\n",
    "# Add normalized score for ranking\n",
    "for sample in stenosis_view:\n",
    "    if sample.radio_uniqueness is not None and sample.radio_representativeness is not None:\n",
    "        u = normalize(sample.radio_uniqueness, min_u, max_u)\n",
    "        r = normalize(sample.radio_representativeness, min_r, max_r)\n",
    "        score = u + r\n",
    "        sample[\"combined_score\"] = score\n",
    "        sample.save()\n",
    "\n",
    "# 3. Select top 300 samples by combined score\n",
    "top300_view = stenosis_view.sort_by(\"combined_score\", reverse=True).limit(300)\n",
    "top300_view.tag_samples(\"top300_for_yolo\")\n",
    "\n",
    "# Optional: Launch view\n",
    "session = fo.launch_app(top300_view, port=5151, auto=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.utils.random as four\n",
    "\n",
    "# Step 1: Split using tags (this modifies the samples in-place)\n",
    "four.random_split(top300_view, {\"train\": 0.8, \"val\": 0.2}, seed=51)\n",
    "\n",
    "# Step 2: Create views using tags\n",
    "train_view = top300_view.match_tags(\"train\")\n",
    "val_view = top300_view.match_tags(\"val\")\n",
    "\n",
    "# Step 3: Extract class labels\n",
    "label_field = \"segmentations\"\n",
    "labels_set = set()\n",
    "for sample in top300_view:\n",
    "    if sample[label_field]:\n",
    "        labels_set.update(d.label for d in sample[label_field].detections)\n",
    "\n",
    "classes = sorted(labels_set)\n",
    "\n",
    "# Step 4: Export each split individually\n",
    "export_dir = \"arcade_yolo_subset\"\n",
    "for split_name, split_view in [(\"train\", train_view), (\"val\", val_view)]:\n",
    "    split_view.export(\n",
    "        export_dir=export_dir,\n",
    "        dataset_type=fo.types.YOLOv5Dataset,\n",
    "        label_field=label_field,\n",
    "        classes=classes,\n",
    "        split=split_name,\n",
    "        overwrite=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Export each split individually\n",
    "export_dir = \"arcade_yolo_subset_coco\"\n",
    "for split_name, split_view in [(\"train\", train_view), (\"val\", val_view)]:\n",
    "    split_view.export(\n",
    "        export_dir=export_dir,\n",
    "        dataset_type=fo.types.COCODetectionDataset,\n",
    "        label_field=label_field,\n",
    "        classes=classes,\n",
    "        split=split_name,\n",
    "        overwrite=False,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "health_care",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
