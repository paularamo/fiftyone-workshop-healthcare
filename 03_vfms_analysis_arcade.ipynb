{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè• Visual AI in Healthcare with FiftyOne ‚Äì VLMs and C-RADIO for ARCADE Dataset\n",
    "**Exploring visual representations in medical datasets with VLMs and embedding search**\n",
    "\n",
    "This notebook is part of the **‚ÄúVisual AI in Healthcare with FiftyOne‚Äù** workshop. Through hands-on examples, we explore how to analyze medical datasets using Visual Language Models (VLMs) and embedding-based search to select representative samples for downstream tasks like fine-tuning object detection models.\n",
    "\n",
    "üî¨ **What you‚Äôll learn in this notebook:**\n",
    "\n",
    "- How to **load the ARCADE dataset** from Hugging Face using FiftyOne utilities  \n",
    "- How to **extract embeddings** using NVIDIA‚Äôs **C-RADIO** embedding model  \n",
    "- How to **perform similarity and uniqueness queries** with FiftyOne Brain  \n",
    "- How to **select the most unique and representative images** for training  \n",
    "- How to **visualize the filtered results** interactively in the FiftyOne App  \n",
    "- How to **export curated datasets** and share them on Hugging Face  \n",
    "\n",
    "üìö **Part of the notebook series:**\n",
    "1. `01_load_arcade_dataset.ipynb` ‚Äì Load and visualize the ARCADE dataset.  \n",
    "2. `02_load_deeplesion_balanced.ipynb` ‚Äì Curate and balance the DeepLesion dataset.  \n",
    "3. `03_vlms_analysis_arcade.ipynb` ‚Äì Use VFMs like NVLabs_CRADIOV3 in dataset undersatnding for ARCADE. \n",
    "4. `04_finetune_yolo8_stenosis.ipynb` ‚Äì Train and integrate YOLOv8 for stenosis detection.  \n",
    "5. `05_medsam2_ct_scan.ipynb` ‚Äì Run MedSAM2 on CT scans for segmentation.  \n",
    "6. `06_nvidia_vista_segmentation.ipynb` ‚Äì Explore NVIDIA-VISTA-3D.  \n",
    "7. `07_medgemma_vqa.ipynb` ‚Äì Perform visual question answering and classification with MedGemma.\n",
    "\n",
    "All notebooks are standalone but are best experienced sequentially.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Load the ARCADE dataset from Hugging Face Hub\n",
    "\n",
    "We begin by importing the ARCADE dataset, a CT angiography dataset curated for stenosis detection, directly from the Hugging Face Hub using FiftyOne's `load_from_hub()` utility.\n",
    "\n",
    "Before loading, we check if a dataset with the same name already exists in your local FiftyOne environment. If it does, we delete it to ensure a clean workspace for this notebook.\n",
    "\n",
    "Key points:\n",
    "\n",
    "- Uses `Voxel51/ARCADE_FO` as the dataset name (FiftyOne handles this internally without slashes)\n",
    "- Ensures no name conflict by deleting any previously loaded dataset with the same name\n",
    "- Downloads the `train` split from Hugging Face for interactive querying and filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing dataset: Voxel51/ARCADE_FO\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "# Name used internally by FiftyOne (it does not use slashes like 'Voxel51/BTCV-...')\n",
    "dataset_name = \"Voxel51/ARCADE_FO\"\n",
    "\n",
    "# Delete the dataset if it exists\n",
    "if fo.dataset_exists(dataset_name):\n",
    "    fo.delete_dataset(dataset_name)\n",
    "    print(f\"Deleted existing dataset: {dataset_name}\")\n",
    "else:\n",
    "    print(f\"No dataset found with name: {dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading config file fiftyone.yml from Voxel51/ARCADE_FO\n",
      "Loading dataset\n",
      "Ignoring unsupported parameter 'splits' for importer type <class 'fiftyone.utils.data.importers.FiftyOneDatasetImporter'>\n",
      "Importing samples...\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [115.2ms elapsed, 0s remaining, 26.2K samples/s]  \n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "from fiftyone.utils.huggingface import load_from_hub\n",
    "\n",
    "dataset = load_from_hub(\n",
    "    \"Voxel51/ARCADE_FO\", split=\"train\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîå Registering a Remotely-Sourced Zoo Model: C-RADIOv3\n",
    "\n",
    "FiftyOne allows you to register and use **remotely-sourced zoo models**, meaning model definitions and configurations can be hosted outside of the FiftyOne codebase ‚Äî for example, in GitHub repositories or public URLs.\n",
    "\n",
    "This capability enables developers and researchers to contribute and share models that are easily accessible and fully compatible with FiftyOne‚Äôs Zoo API.\n",
    "\n",
    "### üí° What is a Remotely-Sourced Zoo Model?\n",
    "\n",
    "Instead of being built-in, a remotely-sourced model is hosted externally but can be registered and used just like native FiftyOne zoo models. You only need to provide a URL to the model's repository or archive.\n",
    "\n",
    "üìå You can register a model source via:\n",
    "- GitHub repository (e.g. `https://github.com/<user>/<repo>`)\n",
    "- GitHub refs (`/tree/<branch>` or `/commit/<sha>`)\n",
    "- Archive URLs (e.g. `.zip`, `.tar.gz`)\n",
    "\n",
    "---\n",
    "\n",
    "### ü§ñ C-RADIOv3 Models\n",
    "\n",
    "In this notebook, we are using a registered model, the [C-RADIOv3 model family](https://github.com/harpreetsahota204/NVLabs_CRADIOV3), created by Harpreet Sahota. These models are designed for **semantic image embeddings** using Vision Transformers and support a variety of architectures and trade-offs between speed and performance.\n",
    "\n",
    "| Model Name              | Description        | Architecture | Patch Size | Best For                          |\n",
    "|-------------------------|--------------------|--------------|------------|-----------------------------------|\n",
    "| `nv_labs/c-radio_v3-b`  | C-RADIOv3-B        | ViT-B/16     | 16√ó16      | Fast inference, moderate accuracy |\n",
    "| `nv_labs/c-radio_v3-l`  | C-RADIOv3-L        | ViT-L/16     | 16√ó16      | Balanced performance              |\n",
    "| `nv_labs/c-radio_v3-h`  | C-RADIOv3-H        | ViT-H/16     | 16√ó16      | High accuracy (recommended)       |\n",
    "| `nv_labs/c-radio_v3-g`  | C-RADIOv3-G        | ViT-H/14     | 14√ó14      | Maximum performance               |\n",
    "\n",
    "Once registered, these models can be directly used via FiftyOne‚Äôs `load_zoo_model()` API for embedding generation, visualization, and semantic search.\n",
    "\n",
    "We‚Äôll explore those capabilities in the next steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you register the zoo model source:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.zoo as foz\n",
    "\n",
    "foz.register_zoo_model_source(\n",
    "    \"https://github.com/harpreetsahota204/NVLabs_CRADIOV3\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, instantiate the model. Let's start with computing embeddings.\n",
    "\n",
    "Note: Refer to the [README](https://github.com/harpreetsahota204/NVLabs_CRADIOV3/blob/main/README.md) for available model checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/paularamos/.cache/torch/hub/NVlabs_RADIO_main\n",
      "Using cache found in /Users/paularamos/.cache/torch/hub/NVlabs_RADIO_main\n"
     ]
    }
   ],
   "source": [
    "radio_embeddings_model = foz.load_zoo_model(\n",
    "    \"nv_labs/c-radio_v3-h\",\n",
    "    feature_format=\"NCHW\", # you can also pass NLC here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compute embeddings as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [47.1m elapsed, 0s remaining, 1.1 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "dataset.compute_embeddings(\n",
    "    model=radio_embeddings_model,\n",
    "    embeddings_field=\"radio_embeddings\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have your embeddings, you can compute the visualization to visualize in the FiftyOne App:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paularamos/Documents/FiftyOne_HealthCare_Workshop/health_care/lib/python3.10/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP( verbose=True)\n",
      "Fri Jul  4 08:41:46 2025 Construct fuzzy simplicial set\n",
      "Fri Jul  4 08:41:50 2025 Finding Nearest Neighbors\n",
      "Fri Jul  4 08:41:52 2025 Finished Nearest Neighbor Search\n",
      "Fri Jul  4 08:41:53 2025 Construct embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  55%| ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     277/500 [00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  0  /  500 epochs\n",
      "\tcompleted  50  /  500 epochs\n",
      "\tcompleted  100  /  500 epochs\n",
      "\tcompleted  150  /  500 epochs\n",
      "\tcompleted  200  /  500 epochs\n",
      "\tcompleted  250  /  500 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed: 100%| ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 500/500 [00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  300  /  500 epochs\n",
      "\tcompleted  350  /  500 epochs\n",
      "\tcompleted  400  /  500 epochs\n",
      "\tcompleted  450  /  500 epochs\n",
      "Fri Jul  4 08:41:54 2025 Finished embedding\n"
     ]
    }
   ],
   "source": [
    "import fiftyone.brain as fob\n",
    "\n",
    " \n",
    "results = fob.compute_visualization(\n",
    "    dataset,\n",
    "    model=radio_embeddings_model,\n",
    "    method=\"umap\",  # \"umap\", \"tsne\", \"pca\", etc\n",
    "    brain_key=\"radio_viz\",\n",
    "    embeddings=\"radio_embeddings\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    }
   ],
   "source": [
    "dataset.reload()\n",
    "dataset.persistent = True\n",
    "\n",
    "# Make sure this is run after all processing\n",
    "session = fo.launch_app(dataset, port=5151, auto=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also build a similarity index over the embeddings to find similar samples in your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.brain as fob\n",
    "\n",
    "results = fob.compute_similarity(\n",
    "    dataset,\n",
    "    model=radio_embeddings_model,\n",
    "    backend=\"sklearn\",  # \"sklearn\", \"qdrant\", \"redis\", etc\n",
    "    brain_key=\"radio_sim\",\n",
    "    embeddings_field=\"radio_embeddings\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your computed embeddings you can also perform other embeddings based workflows such as computing uniqueness values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving embeddings from similarity index...\n",
      "Computing uniqueness...\n",
      "Uniqueness computation complete\n"
     ]
    }
   ],
   "source": [
    "import fiftyone.brain as fob\n",
    "\n",
    "fob.compute_uniqueness(\n",
    "    dataset,\n",
    "    model=radio_embeddings_model,\n",
    "    uniqueness_field=\"radio_uniqueness\",\n",
    "    similarity_index=\"radio_sim\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also compute representativeness scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving embeddings from similarity index...\n",
      "Computing representativeness...\n",
      "Computing clusters for 3000 embeddings; this may take awhile...\n",
      "Representativeness computation complete\n"
     ]
    }
   ],
   "source": [
    "import fiftyone.brain as fob\n",
    "\n",
    "fob.compute_representativeness(\n",
    "    dataset,\n",
    "    model=radio_embeddings_model,\n",
    "    representativeness_field=\"radio_representativeness\",\n",
    "    similarity_index=\"radio_sim\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 most unique\n",
    "unique_view = dataset.sort_by(\"radio_uniqueness\", reverse=True).limit(20)\n",
    "unique_view.tag_samples(\"top_unique\")\n",
    "\n",
    "# Top 20 most representative\n",
    "rep_view = dataset.sort_by(\"radio_representativeness\", reverse=True).limit(20)\n",
    "rep_view.tag_samples(\"top_representative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:        Voxel51/ARCADE_FO\n",
      "Media type:  image\n",
      "Num samples: 3000\n",
      "Persistent:  True\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:                       fiftyone.core.fields.ObjectIdField\n",
      "    filepath:                 fiftyone.core.fields.StringField\n",
      "    tags:                     fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:                 fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:               fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at:         fiftyone.core.fields.DateTimeField\n",
      "    phase:                    fiftyone.core.fields.StringField\n",
      "    task:                     fiftyone.core.fields.StringField\n",
      "    subset_name:              fiftyone.core.fields.StringField\n",
      "    segmentations:            fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    coco_id:                  fiftyone.core.fields.IntField\n",
      "    default_embedding:        fiftyone.core.fields.VectorField\n",
      "    radio_embeddings:         fiftyone.core.fields.VectorField\n",
      "    radio_spatial_features:   fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Heatmap)\n",
      "    radio_uniqueness:         fiftyone.core.fields.FloatField\n",
      "    radio_representativeness: fiftyone.core.fields.FloatField\n"
     ]
    }
   ],
   "source": [
    "dataset.reload()\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Spatial Features\n",
    "\n",
    "You can also compute spatial features. To use this feature you need to set `output_type=\"spatial\"`, additionally spatial features only supports `feature_format=\"NCHW\"`.\n",
    "\n",
    "You can choose to do some Gaussian smoothing if you'd like, just set `apply_smoothing=True` and choose a value for `smoothing_sigma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/paularamos/.cache/torch/hub/NVlabs_RADIO_main\n",
      "Using cache found in /Users/paularamos/.cache/torch/hub/NVlabs_RADIO_main\n"
     ]
    }
   ],
   "source": [
    "radio_spatial_model = foz.load_zoo_model(\n",
    "    \"nv_labs/c-radio_v3-h\",\n",
    "    output_type=\"spatial\",\n",
    "    apply_smoothing=True, # if you want smoothing\n",
    "    smoothing_sigma=0.8, # how much smoothing you want to apply\n",
    "    feature_format=\"NCHW\" #this is the required for the heatmap\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we are using the `apply_model` method here, as we are not computing 1D embeddings like above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [43.1m elapsed, 0s remaining, 1.2 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "dataset.apply_model(\n",
    "    radio_spatial_model,\n",
    "    \"radio_spatial_features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view your results in the app like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset:          Voxel51/ARCADE_FO\n",
       "Media type:       image\n",
       "Num samples:      3000\n",
       "Selected samples: 0\n",
       "Selected labels:  0\n",
       "Session URL:      http://localhost:5151/"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fo.launch_app(dataset, port=5151, auto=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:        Voxel51/ARCADE_FO\n",
      "Media type:  image\n",
      "Num samples: 3000\n",
      "Persistent:  True\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:                     fiftyone.core.fields.ObjectIdField\n",
      "    filepath:               fiftyone.core.fields.StringField\n",
      "    tags:                   fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:               fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:             fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at:       fiftyone.core.fields.DateTimeField\n",
      "    phase:                  fiftyone.core.fields.StringField\n",
      "    task:                   fiftyone.core.fields.StringField\n",
      "    subset_name:            fiftyone.core.fields.StringField\n",
      "    segmentations:          fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    coco_id:                fiftyone.core.fields.IntField\n",
      "    default_embedding:      fiftyone.core.fields.VectorField\n",
      "    radio_embeddings:       fiftyone.core.fields.VectorField\n",
      "    radio_spatial_features: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Heatmap)\n"
     ]
    }
   ],
   "source": [
    "dataset.persistent=True\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    }
   ],
   "source": [
    "## Creating a subset for finetuning:\n",
    "\n",
    "# 1. Filter samples where task == \"stenosis\"\n",
    "stenosis_view = dataset.match({\"task\": \"stenosis\"})\n",
    "\n",
    "# 2. Sort by both uniqueness and representativeness\n",
    "# Normalize values for fairness in ranking\n",
    "import numpy as np\n",
    "\n",
    "uniqueness_values = [s[\"radio_uniqueness\"] for s in stenosis_view if s[\"radio_uniqueness\"] is not None]\n",
    "representativeness_values = [s[\"radio_representativeness\"] for s in stenosis_view if s[\"radio_representativeness\"] is not None]\n",
    "\n",
    "# Min-max normalization\n",
    "min_u, max_u = min(uniqueness_values), max(uniqueness_values)\n",
    "min_r, max_r = min(representativeness_values), max(representativeness_values)\n",
    "\n",
    "def normalize(val, min_val, max_val):\n",
    "    return (val - min_val) / (max_val - min_val + 1e-8)\n",
    "\n",
    "# Add normalized score for ranking\n",
    "for sample in stenosis_view:\n",
    "    if sample.radio_uniqueness is not None and sample.radio_representativeness is not None:\n",
    "        u = normalize(sample.radio_uniqueness, min_u, max_u)\n",
    "        r = normalize(sample.radio_representativeness, min_r, max_r)\n",
    "        score = u + r\n",
    "        sample[\"combined_score\"] = score\n",
    "        sample.save()\n",
    "\n",
    "# 3. Select top 300 samples by combined score\n",
    "top300_view = stenosis_view.sort_by(\"combined_score\", reverse=True).limit(300)\n",
    "top300_view.tag_samples(\"top300_for_yolo\")\n",
    "\n",
    "# Optional: Launch view\n",
    "session = fo.launch_app(top300_view, port=5151, auto=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 299/299 [484.5ms elapsed, 0s remaining, 617.1 samples/s]      \n",
      "Directory 'arcade_yolo_subset' already exists; export will be merged with existing files\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 179/179 [252.4ms elapsed, 0s remaining, 709.2 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.utils.random as four\n",
    "\n",
    "# Step 1: Split using tags (this modifies the samples in-place)\n",
    "four.random_split(top300_view, {\"train\": 0.8, \"val\": 0.2}, seed=51)\n",
    "\n",
    "# Step 2: Create views using tags\n",
    "train_view = top300_view.match_tags(\"train\")\n",
    "val_view = top300_view.match_tags(\"val\")\n",
    "\n",
    "# Step 3: Extract class labels\n",
    "label_field = \"segmentations\"\n",
    "labels_set = set()\n",
    "for sample in top300_view:\n",
    "    if sample[label_field]:\n",
    "        labels_set.update(d.label for d in sample[label_field].detections)\n",
    "\n",
    "classes = sorted(labels_set)\n",
    "\n",
    "# Step 4: Export each split individually\n",
    "export_dir = \"arcade_yolo_subset\"\n",
    "for split_name, split_view in [(\"train\", train_view), (\"val\", val_view)]:\n",
    "    split_view.export(\n",
    "        export_dir=export_dir,\n",
    "        dataset_type=fo.types.YOLOv5Dataset,\n",
    "        label_field=label_field,\n",
    "        classes=classes,\n",
    "        split=split_name,\n",
    "        overwrite=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring unsupported parameter 'split'\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 299/299 [2.1s elapsed, 0s remaining, 305.7 samples/s]      \n",
      "Directory 'arcade_yolo_subset_coco' already exists; export will be merged with existing files\n",
      "Ignoring unsupported parameter 'split'\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 179/179 [544.7ms elapsed, 0s remaining, 328.6 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# Step 4: Export each split individually\n",
    "export_dir = \"arcade_yolo_subset_coco\"\n",
    "for split_name, split_view in [(\"train\", train_view), (\"val\", val_view)]:\n",
    "    split_view.export(\n",
    "        export_dir=export_dir,\n",
    "        dataset_type=fo.types.COCODetectionDataset,\n",
    "        label_field=label_field,\n",
    "        classes=classes,\n",
    "        split=split_name,\n",
    "        overwrite=False,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "health_care",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
