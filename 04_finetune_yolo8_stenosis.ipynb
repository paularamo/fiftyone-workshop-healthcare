{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¥ Visual AI in Healthcare with FiftyOne â€“ Fine-tuning YOLOv8 for Stenosis Detection  \n",
    "**Train, evaluate, and visualize a YOLOv8 object detection model using the curated ARCADE dataset**\n",
    "\n",
    "This notebook is part of the **â€œVisual AI in Healthcare with FiftyOneâ€** workshop. In this hands-on exercise, you'll learn how to fine-tune a YOLOv8 object detection model for stenosis detection using a subset of the ARCADE dataset. The subset is curated through embedding-based selection methods described in previous notebooks. This notebook demonstrates how to fine-tune a YOLOv8 model on a curated subset of 300 images with `stenosis` from the ARCADE dataset using FiftyOne and Ultralytics' YOLOv8 integration.\n",
    "\n",
    "ðŸ§  **What youâ€™ll learn in this notebook:**\n",
    "\n",
    "- How to **prepare and export a YOLOv8-compatible dataset** from FiftyOne  \n",
    "- How to **fine-tune YOLOv8** on a small but representative subset  \n",
    "- How to **run inference on test data** using the fine-tuned model  \n",
    "- How to **load predictions into FiftyOne** for evaluation  \n",
    "- How to **compare model predictions** with ground truth annotations  \n",
    "\n",
    "ðŸ“š **Part of the notebook series:**\n",
    "1. `01_load_arcade_dataset.ipynb` â€“ Load and visualize the ARCADE dataset.  \n",
    "2. `02_load_deeplesion_balanced.ipynb` â€“ Curate and balance the DeepLesion dataset.  \n",
    "3. `03_vlms_analysis_arcade.ipynb` â€“ Use VFMs like NVLabs_CRADIOV3 in dataset undersatnding for ARCADE. \n",
    "4. `04_finetune_yolo8_stenosis.ipynb` â€“ Train and integrate YOLOv8 for stenosis detection.  \n",
    "5. `05_medsam2_ct_scan.ipynb` â€“ Run MedSAM2 on CT scans for segmentation.  \n",
    "6. `06_nvidia_vista_segmentation.ipynb` â€“ Explore NVIDIA-VISTA-3D.  \n",
    "7. `07_medgemma_vqa.ipynb` â€“ Perform visual question answering and classification with MedGemma.\n",
    "\n",
    "All notebooks are standalone but are best experienced sequentially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Requirements\n",
    "\n",
    "Please install all the requeriments for running this notebook. And import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Imports\n",
    "import fiftyone as fo\n",
    "import fiftyone.utils.random as four\n",
    "from ultralytics import YOLO\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“¦ Load and Prepare the ARCADE Subset for Fine-Tuning\n",
    "\n",
    "In this step, we prepare the curated subset of the ARCADE dataset for training a YOLOv8 model.\n",
    "\n",
    "- We first **check if an existing FiftyOne dataset** with the same name exists and delete it if necessary to avoid conflicts.\n",
    "- Then we **load the dataset** from disk using the `YOLOv5Dataset` format (supported in FiftyOne for YOLOv5/YOLOv8-style annotations).\n",
    "- The dataset is then **launched in the FiftyOne App** for visual inspection.\n",
    "- Next, we **split the dataset** into training and validation sets (80/20) using `fiftyone.utils.random`.\n",
    "- Finally, we **extract the class labels** from the segmentation annotations and **export** the dataset back to disk in YOLO format, ready for training.\n",
    "\n",
    "> ðŸ“Œ Note: This step assumes you previously exported the curated subset of ARCADE using FiftyOne. The loaded dataset will be used to fine-tune a YOLOv8 object detection model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the existing dataset\n",
    "#dataset_name = \"arcade_subset_loaded\"\n",
    "dataset_name = \"arcade_subset_test\"\n",
    "\n",
    "\n",
    "# Delete it if it exists\n",
    "if fo.dataset_exists(dataset_name):\n",
    "    fo.delete_dataset(dataset_name)\n",
    "    print(f\"Deleted existing dataset: {dataset_name}\")\n",
    "else:\n",
    "    print(f\"No dataset found with name: {dataset_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.types as fot\n",
    "\n",
    "# Define the path to your exported YOLOv8 dataset\n",
    "dataset_dir = \"arcade_yolo_subset\"  # <-- this should match your previous export_dir\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.types as fot\n",
    "\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_dir=\"arcade_yolo_subset\",\n",
    "    dataset_type=fot.YOLOv5Dataset,\n",
    "    split=\"train\",  # match what was exported\n",
    "    label_field=\"segmentations\",\n",
    "    name=\"arcade_subset_loaded\",\n",
    ")\n",
    "# Launch FiftyOne App to visualize\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train/Val Split (80/20)\n",
    "dataset.untag_samples(dataset.distinct(\"tags\"))\n",
    "four.random_split(dataset, {\"train\": 0.8, \"val\": 0.2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Extract Classes from Segmentations\n",
    "label_field = \"segmentations\"\n",
    "classes = sorted({\n",
    "    det.label\n",
    "    for sample in dataset.select_fields(label_field)\n",
    "    if sample[label_field] is not None\n",
    "    for det in sample[label_field].detections\n",
    "})\n",
    "print(\"Classes:\", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Export to YOLO Format\n",
    "export_dir = \"./arcade_yolo\"\n",
    "export_yolo_data(\n",
    "    dataset,\n",
    "    export_dir,\n",
    "    classes=classes,\n",
    "    label_field=label_field,\n",
    "    split=[\"train\", \"val\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ‹ï¸ Fine-Tune the YOLOv8 Model (Run in Terminal)\n",
    "\n",
    "Now that the dataset is prepared and exported in YOLO format, we fine-tune a YOLOv8 model using the [Ultralytics CLI](https://docs.ultralytics.com/cli/train/).\n",
    "\n",
    "The command below uses the `yolov8n.pt` (YOLOv8 Nano) pretrained model and trains it on our exported dataset:\n",
    "\n",
    "```bash\n",
    "yolo task=detect mode=train \\\n",
    "  model=yolov8n.pt \\\n",
    "  data=arcade_yolo/dataset.yaml \\\n",
    "  epochs=60 imgsz=640 batch=16\n",
    "```\n",
    "\n",
    "Follow this [documentation](https://docs.voxel51.com/tutorials/yolov8.html?highlight=fine%20tune) for Fine-Tuning process with Ultralytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=train model=yolov8n.pt data=arcade_yolo_subset/dataset.yaml epochs=60 imgsz=640 batch=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference with Fine-Tuned YOLOv8 Model\n",
    "\n",
    "Once training is complete, we can use the best weights to run inference on the validation set. The following command uses the `yolo` CLI to perform predictions:\n",
    "\n",
    "```bash\n",
    "!yolo task=detect mode=predict \\\n",
    "  model=/path/ultralyrics/results/runs/detect/train2/weights/best.pt \\\n",
    "  source=arcade_yolo_subset/images/val \\\n",
    "  save_txt=True \\\n",
    "  save_conf=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=predict model=/path/ultralyrics/results/runs/detect/train2/weights/best.pt source=arcade_yolo_subset/images/val save_txt=True save_conf=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Predictions into FiftyOne\n",
    "\n",
    "After running inference, we now load the predictions into our FiftyOne dataset for visualization and evaluation.\n",
    "\n",
    "### Step 1: Load the validation split of the YOLOv5-style dataset\n",
    "\n",
    "We use FiftyOne's `Dataset.from_dir()` method to load the validation set from the `arcade_yolo_subset` directory. The dataset is in `YOLOv5Dataset` format. We assign the labels to the `ground_truth` field for later comparison.\n",
    "\n",
    "This allows us to later visualize both the ground truth and the predicted detections in the same FiftyOne session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.utils.yolo as fouy\n",
    "\n",
    "# Load original dataset\n",
    "dataset_ = fo.Dataset.from_dir(\n",
    "    dataset_dir=\"arcade_yolo_subset\",\n",
    "    dataset_type=fo.types.YOLOv5Dataset,\n",
    "    split=\"val\",\n",
    "    label_field=\"ground_truth\",\n",
    "    name=\"arcade_subset_test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define utility functions to read and convert YOLOv8 predictions\n",
    "\n",
    "We define the following helper functions:\n",
    "\n",
    "- `get_prediction_filepath`: builds the filepath to the YOLOv8 prediction `.txt` file corresponding to each image.\n",
    "- `read_yolo_detections_file`: reads a prediction `.txt` file and extracts bounding box data.\n",
    "- `convert_yolo_detections_to_fiftyone`: converts YOLO-format detections into FiftyOne's `Detection` objects.\n",
    "- `_uncenter_boxes`: converts YOLO box format (center x/y, width, height) to FiftyOne box format (top-left x/y, width, height).\n",
    "- `_get_class_labels`: maps YOLO class indices to class labels using the dataset's class list.\n",
    "\n",
    "These functions are used to transform YOLOv8 predictions into a format that can be visualized and analyzed within FiftyOne.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_filepath(filepath, run_number = 1):\n",
    "    run_num_string = \"\"\n",
    "    if run_number != 1:\n",
    "        run_num_string = str(run_number)\n",
    "    filename = filepath.split(\"/\")[-1].split(\".\")[0]\n",
    "    return f\"/Users/paularamos/Documents/GitHub/awesome-fiftyone/runs/detect/predict/labels/{filename}.txt\"\n",
    "\n",
    "def add_yolo_detections(\n",
    "    samples,\n",
    "    prediction_field,\n",
    "    prediction_filepath,\n",
    "    class_list\n",
    "    ):\n",
    "\n",
    "    prediction_filepaths = samples.values(prediction_filepath)\n",
    "    yolo_detections = [read_yolo_detections_file(pf) for pf in prediction_filepaths]\n",
    "    detections =  [convert_yolo_detections_to_fiftyone(yd, class_list) for yd in yolo_detections]\n",
    "    samples.set_values(prediction_field, detections)\n",
    "\n",
    "def read_yolo_detections_file(filepath):\n",
    "    detections = []\n",
    "    if not os.path.exists(filepath):\n",
    "        return np.array([])\n",
    "\n",
    "    with open(filepath) as f:\n",
    "        lines = [line.rstrip('\\n').split(' ') for line in f]\n",
    "\n",
    "    for line in lines:\n",
    "        detection = [float(l) for l in line]\n",
    "        detections.append(detection)\n",
    "    return np.array(detections)\n",
    "\n",
    "def convert_yolo_detections_to_fiftyone(\n",
    "    yolo_detections,\n",
    "    class_list\n",
    "    ):\n",
    "\n",
    "    detections = []\n",
    "    if yolo_detections.size == 0:\n",
    "        return fo.Detections(detections=detections)\n",
    "\n",
    "    boxes = yolo_detections[:, 1:-1]\n",
    "    _uncenter_boxes(boxes)\n",
    "\n",
    "    confs = yolo_detections[:, -1]\n",
    "    labels = _get_class_labels(yolo_detections[:, 0], class_list)\n",
    "\n",
    "    for label, conf, box in zip(labels, confs, boxes):\n",
    "        detections.append(\n",
    "            fo.Detection(\n",
    "                label=label,\n",
    "                bounding_box=box.tolist(),\n",
    "                confidence=conf\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return fo.Detections(detections=detections)\n",
    "\n",
    "def _uncenter_boxes(boxes):\n",
    "    '''convert from center coords to corner coords'''\n",
    "    boxes[:, 0] -= boxes[:, 2]/2.\n",
    "    boxes[:, 1] -= boxes[:, 3]/2.\n",
    "\n",
    "def _get_class_labels(predicted_classes, class_list):\n",
    "    labels = (predicted_classes).astype(int)\n",
    "    labels = [class_list[l] for l in labels]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Load YOLOv8 predictions and add them to the dataset\n",
    "\n",
    "We generate the list of prediction filepaths for the images in the validation split using `get_prediction_filepath`.\n",
    "\n",
    "Then, we use `add_yolo_detections()` to load predictions from disk, convert them to FiftyOne `Detection` objects, and attach them to each sample under the field `yolov8n_arcade`.\n",
    "\n",
    "This prepares the dataset for qualitative or quantitative evaluation of YOLOv8 predictions within FiftyOne.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "filepaths = dataset_.values(\"filepath\")\n",
    "prediction_filepaths = [get_prediction_filepath(fp, run_number=2) for fp in filepaths]\n",
    "\n",
    "dataset_.set_values(\n",
    "    \"yolov8n_arcade_det_filepath\",\n",
    "    prediction_filepaths\n",
    ")\n",
    "\n",
    "add_yolo_detections(\n",
    "    dataset_,\n",
    "    \"yolov8n_arcade\",\n",
    "    \"yolov8n_arcade_det_filepath\",\n",
    "    classes\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset_, port=5151, auto=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating YOLOv8 Results with FiftyOne Plugins\n",
    "\n",
    "FiftyOne supports powerful evaluation capabilities through its plugin system. With the [`@voxel51/evaluation`](https://github.com/voxel51/fiftyone-plugins) plugin, you can evaluate detection, classification, segmentation, and regression models directly from the UI or Python SDK.\n",
    "\n",
    "#### ðŸ”Œ Plugin Installation\n",
    "\n",
    "To install the evaluation plugin, run the following command in your terminal:\n",
    "\n",
    "```bash\n",
    "fiftyone plugins download \\\n",
    "  https://github.com/voxel51/fiftyone-plugins \\\n",
    "  --plugin-names @voxel51/evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Detection Evaluation on YOLOv8 Predictions\n",
    "\n",
    "Now that our YOLOv8 predictions are added to the dataset, we can evaluate them against the ground truth using FiftyOne's built-in `evaluate_detections` method.\n",
    "\n",
    "In this example, we disable mAP computation (`compute_mAP=False`) since the predictions do not contain confidence scores.\n",
    "\n",
    "```python\n",
    "results = dataset_.evaluate_detections(\n",
    "    \"yolov8n_arcade\",          # field with model predictions\n",
    "    gt_field=\"ground_truth\",   # ground truth field\n",
    "    eval_key=\"eval_no_conf\",   # identifier for this evaluation run\n",
    "    compute_mAP=False          # skips mAP since we don't have confidence scores\n",
    ")\n",
    "\n",
    "results.print_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dataset_.evaluate_detections(\n",
    "    \"yolov8n_arcade\",\n",
    "    gt_field=\"ground_truth\",\n",
    "    eval_key=\"eval_no_conf\",\n",
    "    compute_mAP=False,  # Avoids needing confidence\n",
    ")\n",
    "results.print_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_.reload()\n",
    "dataset_.persistent=True\n",
    "print(dataset_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "health_care",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
