{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cedd252",
   "metadata": {},
   "source": [
    "# üè• Visual AI in Healthcare with FiftyOne - ARCADE Dataset Loading/Exploration\n",
    "**Empowering medical imaging workflows with open-source tools and modern AI**\n",
    "\n",
    "This notebook is part of the **‚ÄúVisual AI in Healthcare with FiftyOne‚Äù** workshop. Through hands-on examples, we explore how to load, visualize, analyze, and enhance medical imaging datasets using state-of-the-art AI tools.\n",
    "\n",
    "üî¨ **What you‚Äôll learn in this notebook:**\n",
    "\n",
    "- How to **load and organize a multi-task medical imaging dataset** (ARCADE) using FiftyOne  \n",
    "- How to **import COCO-style segmentation annotations** for both segmentation and stenosis detection tasks  \n",
    "- How to **tag and enrich samples with metadata** for easier querying and filtering  \n",
    "- How to **merge multiple subsets** into a single persistent FiftyOne dataset  \n",
    "- How to **compute image embeddings** using FiftyOne Brain for exploratory analysis and visualization  \n",
    "- How to **launch the FiftyOne App** for interactive dataset exploration\n",
    "- How to **export your dataser** and **load it to Hugging Face**\n",
    "\n",
    "üìö **Part of the notebook series:**\n",
    "1. `01_load_arcade_dataset.ipynb` ‚Äì Load and visualize the ARCADE dataset.  \n",
    "2. `02_load_deeplesion_balanced.ipynb` ‚Äì Curate and balance the DeepLesion dataset.  \n",
    "3. `03_vlms_analysis_arcade.ipynb` ‚Äì Use VFMs like NVLabs_CRADIOV3 in dataset undersatnding for ARCADE. \n",
    "4. `04_finetune_yolo8_stenosis.ipynb` ‚Äì Train and integrate YOLOv8 for stenosis detection.  \n",
    "5. `05_medsam2_ct_scan.ipynb` ‚Äì Run MedSAM2 on CT scans for segmentation.  \n",
    "6. `06_nvidia_vista_segmentation.ipynb` ‚Äì Explore NVIDIA-VISTA-3D.  \n",
    "7. `07_medgemma_vqa.ipynb` ‚Äì Perform visual question answering and classification with MedGemma.\n",
    "\n",
    "All notebooks are standalone but are best experienced sequentially."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1617b3c",
   "metadata": {},
   "source": [
    "### ‚úÖ Requirements\n",
    "\n",
    "Please install all the requeriments for running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf035127",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets fiftyone pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71f2347",
   "metadata": {},
   "source": [
    "### üóÇÔ∏è Loading and Merging ARCADE Dataset Subsets into FiftyOne\n",
    "\n",
    "The ARCADE challenge includes multiple datasets across two key tasks ‚Äî **segmentation** and **stenosis detection** ‚Äî spread across training, validation, and test phases. This section consolidates all subsets into a single FiftyOne dataset to simplify exploration and analysis. Download the dataset [here](https://zenodo.org/api/records/8386059/files-archive) and uncompress that where you have this repo installed with a folder called `arcade_challenge_datasets`.\n",
    "\n",
    "#### üîç What's happening here:\n",
    "\n",
    "- Defines the paths and structure for the **segmentation** and **stenosis** datasets across training, validation, and final test phases.\n",
    "- Initializes a new dataset called `\"arcade_combined\"` and deletes any prior version with the same name.\n",
    "- **Adds custom fields** to the dataset schema:\n",
    "  - `phase` ‚Äì e.g., `phase_1`, `final_phase`\n",
    "  - `task` ‚Äì either `segmentation` or `stenosis`\n",
    "  - `subset_name` ‚Äì specific subset like `seg_train` or `sten_val`\n",
    "- For each subset:\n",
    "  - Loads annotations in COCO format using `COCODetectionDatasetImporter`\n",
    "  - Creates a temporary dataset and populates it with images and labels\n",
    "  - Assigns field values and adds sample-level tags\n",
    "  - Merges the processed samples into the main dataset\n",
    "  - Deletes the temporary dataset after merging\n",
    "\n",
    "This structure allows for **highly flexible querying** (e.g., \"show all stenosis test cases\") and enables rich filtering and visualization workflows in FiftyOne.g\n",
    "\n",
    "This creates a unified dataset in FiftyOne where you can filter by phase, task type, or subset name, setting the foundation for structured medical image analysis and model evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2ff7b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paularamos/Documents/fiftyone-workshop-healthcare-test/fo_healthcare_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Loading seg_train...\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [3.2s elapsed, 0s remaining, 316.6 samples/s]      \n",
      "\n",
      "üì¶ Loading seg_val...\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [688.3ms elapsed, 0s remaining, 290.6 samples/s]      \n",
      "\n",
      "üì¶ Loading sten_train...\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [1.3s elapsed, 0s remaining, 757.7 samples/s]         \n",
      "\n",
      "üì¶ Loading sten_val...\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [332.4ms elapsed, 0s remaining, 601.7 samples/s]      \n",
      "\n",
      "üì¶ Loading test_case_seg...\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [1.1s elapsed, 0s remaining, 272.4 samples/s]         \n",
      "\n",
      "üì¶ Loading test_case_sten...\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [374.6ms elapsed, 0s remaining, 802.5 samples/s]     \n",
      "\n",
      "‚úÖ All subsets imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fiftyone as fo\n",
    "from fiftyone.utils.coco import COCODetectionDatasetImporter\n",
    "\n",
    "# Base path\n",
    "base_path = \"arcade_challenge_datasets\"\n",
    "combined_dataset_name = \"arcade_combined\"\n",
    "\n",
    "# Dataset config\n",
    "datasets = [\n",
    "    (\"seg_train\", \"dataset_phase_1/segmentation_dataset/seg_train\", \"phase_1\", \"segmentation\"),\n",
    "    (\"seg_val\", \"dataset_phase_1/segmentation_dataset/seg_val\", \"phase_1\", \"segmentation\"),\n",
    "    (\"sten_train\", \"dataset_phase_1/stenosis_dataset/sten_train\", \"phase_1\", \"stenosis\"),\n",
    "    (\"sten_val\", \"dataset_phase_1/stenosis_dataset/sten_val\", \"phase_1\", \"stenosis\"),\n",
    "    (\"test_case_seg\", \"dataset_final_phase/test_case_segmentation\", \"final_phase\", \"segmentation\"),\n",
    "    (\"test_case_sten\", \"dataset_final_phase/test_cases_stenosis\", \"final_phase\", \"stenosis\"),\n",
    "]\n",
    "\n",
    "# Delete existing dataset\n",
    "if fo.dataset_exists(combined_dataset_name):\n",
    "    fo.delete_dataset(combined_dataset_name)\n",
    "combined_dataset = fo.Dataset(combined_dataset_name)\n",
    "\n",
    "# Add metadata fields\n",
    "combined_dataset.add_sample_field(\"phase\", fo.StringField)\n",
    "combined_dataset.add_sample_field(\"task\", fo.StringField)\n",
    "combined_dataset.add_sample_field(\"subset_name\", fo.StringField)\n",
    "\n",
    "# Load each dataset separately and assign fields\n",
    "for subset_name, relative_path, phase, task in datasets:\n",
    "    print(f\"\\nüì¶ Loading {subset_name}...\")\n",
    "\n",
    "    image_dir = os.path.join(base_path, relative_path, \"images\")\n",
    "    annotation_dir = os.path.join(base_path, relative_path, \"annotations\")\n",
    "    json_files = [f for f in os.listdir(annotation_dir) if f.endswith(\".json\")]\n",
    "    assert len(json_files) == 1, f\"Expected 1 JSON in {annotation_dir}, found {len(json_files)}\"\n",
    "    labels_path = os.path.join(annotation_dir, json_files[0])\n",
    "\n",
    "    # Create temporary dataset\n",
    "    temp_dataset_name = f\"{combined_dataset_name}_{subset_name}\"\n",
    "    if fo.dataset_exists(temp_dataset_name):\n",
    "        fo.delete_dataset(temp_dataset_name)\n",
    "    temp_dataset = fo.Dataset(temp_dataset_name)\n",
    "\n",
    "    importer = COCODetectionDatasetImporter(\n",
    "        data_path=image_dir,\n",
    "        labels_path=labels_path,\n",
    "        label_types=\"segmentations\",\n",
    "        \n",
    "        include_id=True,\n",
    "        extra_attrs=True,\n",
    "    )\n",
    "\n",
    "    # Add to temp dataset\n",
    "    temp_dataset.add_importer(importer)\n",
    "\n",
    "    # Tag + assign fields\n",
    "    for sample in temp_dataset:\n",
    "        sample[\"phase\"] = phase\n",
    "        sample[\"task\"] = task\n",
    "        sample[\"subset_name\"] = subset_name\n",
    "        sample.tags.extend([subset_name, task, phase])\n",
    "        sample.save()\n",
    "        combined_dataset.add_sample(sample)\n",
    "\n",
    "    # Delete temp dataset\n",
    "    temp_dataset.delete()\n",
    "\n",
    "print(\"\\n‚úÖ All subsets imported successfully!\")\n",
    "\n",
    "# Optional: launch FiftyOne app\n",
    "# fo.launch_app(combined_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3156f39d",
   "metadata": {},
   "source": [
    "### üß† Computing and Visualizing Embeddings with FiftyOne Brain\n",
    "\n",
    "Once the full ARCADE dataset has been assembled, this section applies **embedding generation and visualization** techniques using FiftyOne Brain. Embeddings are vector representations of images or patches that capture visual similarity and semantic content, enabling advanced tasks like clustering, outlier detection, and semantic search.\n",
    "\n",
    "#### üóÇ Step 1: Persist and Launch the App\n",
    "- We make the dataset **persistent** so it can be reloaded later.\n",
    "- The FiftyOne App is launched for interactive exploration of the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f658e9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    }
   ],
   "source": [
    "combined_dataset.persistent=True\n",
    "session = fo.launch_app(combined_dataset, port=5151, auto=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628dce65",
   "metadata": {},
   "source": [
    "#### üß† Step 2: Compute Embeddings for Entire Images\n",
    "- Uses FiftyOne Brain‚Äôs `compute_visualization()` to generate **default embeddings** for each image.\n",
    "- These are stored under the `\"default_embedding\"` key and indexed using the `\"arcade_emb\"` brain key.\n",
    "- This allows for visualizing the full dataset in **2D latent space** (e.g., t-SNE or UMAP projection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a106818a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings...\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [4.8m elapsed, 0s remaining, 10.8 samples/s]      \n",
      "Generating visualization...\n",
      "UMAP( verbose=True)\n",
      "Tue Jul 15 16:31:26 2025 Construct fuzzy simplicial set\n",
      "Tue Jul 15 16:31:29 2025 Finding Nearest Neighbors\n",
      "Tue Jul 15 16:31:30 2025 Finished Nearest Neighbor Search\n",
      "Tue Jul 15 16:31:31 2025 Construct embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  53%| ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     265/500 [00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  0  /  500 epochs\n",
      "\tcompleted  50  /  500 epochs\n",
      "\tcompleted  100  /  500 epochs\n",
      "\tcompleted  150  /  500 epochs\n",
      "\tcompleted  200  /  500 epochs\n",
      "\tcompleted  250  /  500 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed: 100%| ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 500/500 [00:01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  300  /  500 epochs\n",
      "\tcompleted  350  /  500 epochs\n",
      "\tcompleted  400  /  500 epochs\n",
      "\tcompleted  450  /  500 epochs\n",
      "Tue Jul 15 16:31:32 2025 Finished embedding\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fiftyone.brain.visualization.VisualizationResults at 0x3342a3250>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import fiftyone as fo\n",
    "import fiftyone.brain as fob\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "# Load dataset\n",
    "#dataset = fo.load_dataset(\"deeplesion\")\n",
    "\n",
    "# Compute embeddings for all samples\n",
    "fob.compute_visualization(\n",
    "    combined_dataset,\n",
    "    embeddings=\"default_embedding\",\n",
    "    brain_key=\"arcade_emb\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71718b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:        arcade_combined\n",
      "Media type:  image\n",
      "Num samples: 3000\n",
      "Persistent:  True\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:                fiftyone.core.fields.ObjectIdField\n",
      "    filepath:          fiftyone.core.fields.StringField\n",
      "    tags:              fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:          fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:        fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at:  fiftyone.core.fields.DateTimeField\n",
      "    phase:             fiftyone.core.fields.StringField\n",
      "    task:              fiftyone.core.fields.StringField\n",
      "    subset_name:       fiftyone.core.fields.StringField\n",
      "    segmentations:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    coco_id:           fiftyone.core.fields.IntField\n",
      "    default_embedding: fiftyone.core.fields.VectorField\n"
     ]
    }
   ],
   "source": [
    "print(combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4759ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset.persistent=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ac60f4",
   "metadata": {},
   "source": [
    "#### üß© Step 3: Compute Patch-Level Embeddings (Optional)\n",
    "- Instead of entire images, we compute embeddings for **regions of interest**, such as segmentations.\n",
    "- Specifies the patch field (`\"segmentations\"`) to extract ROIs.\n",
    "- Loads a pretrained model (`mobilenet-v2-imagenet-torch`) from the FiftyOne Model Zoo.\n",
    "- Computes embeddings for each patch and stores them under `\"patches_embedding\"`, with a new brain key `\"patches_emb\"`.\n",
    "\n",
    "These visual embeddings enable deep visual exploration and analysis of ARCADE‚Äôs segmentation and stenosis data, surfacing patterns and anomalies that go beyond raw pixel inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "900e9205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [12.8m elapsed, 0s remaining, 12.2 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# Specify the field containing the patches (e.g., detections)\n",
    "patches_field = \"segmentations\"\n",
    "\n",
    "# Option 1: Use a pre-trained model from the FiftyOne Model Zoo\n",
    "model = foz.load_zoo_model(\"mobilenet-v2-imagenet-torch\")\n",
    "\n",
    "# Compute embeddings for the patches using the specified model\n",
    "combined_dataset.compute_patch_embeddings(\n",
    "    patches_field=patches_field, \n",
    "    model=model, \n",
    "    embeddings_field=\"patches_embedding\",\n",
    "    num_workers=0\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd43317b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating visualization...\n",
      "UMAP( verbose=True)\n",
      "Tue Jul 15 17:03:45 2025 Construct fuzzy simplicial set\n",
      "Tue Jul 15 17:03:45 2025 Finding Nearest Neighbors\n",
      "Tue Jul 15 17:03:45 2025 Building RP forest with 10 trees\n",
      "Tue Jul 15 17:03:47 2025 NN descent for 13 iterations\n",
      "\t 1  /  13\n",
      "\t 2  /  13\n",
      "\t 3  /  13\n",
      "\t 4  /  13\n",
      "\tStopping threshold met -- exiting after 4 iterations\n",
      "Tue Jul 15 17:03:51 2025 Finished Nearest Neighbor Search\n",
      "Tue Jul 15 17:03:51 2025 Construct embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  22%| ‚ñà‚ñà‚ñé        45/200 [00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  0  /  200 epochs\n",
      "\tcompleted  20  /  200 epochs\n",
      "\tcompleted  40  /  200 epochs\n",
      "\tcompleted  60  /  200 epochs\n",
      "\tcompleted  80  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  89%| ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  178/200 [00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  100  /  200 epochs\n",
      "\tcompleted  120  /  200 epochs\n",
      "\tcompleted  140  /  200 epochs\n",
      "\tcompleted  160  /  200 epochs\n",
      "\tcompleted  180  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed: 100%| ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 200/200 [00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 15 17:03:52 2025 Finished embedding\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fiftyone.brain.visualization.VisualizationResults at 0x3344ddab0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fob.compute_visualization(\n",
    "    combined_dataset,\n",
    "    patches_field=\"segmentations\",             # üëà your field\n",
    "    embeddings=\"patches_embedding\",            # üëà patch embedding field\n",
    "    brain_key=\"segmentations_patch_embeddings\",# üëà name for this embedding run\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a01c2890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:        arcade_combined\n",
      "Media type:  image\n",
      "Num samples: 3000\n",
      "Persistent:  True\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:                fiftyone.core.fields.ObjectIdField\n",
      "    filepath:          fiftyone.core.fields.StringField\n",
      "    tags:              fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:          fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:        fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at:  fiftyone.core.fields.DateTimeField\n",
      "    phase:             fiftyone.core.fields.StringField\n",
      "    task:              fiftyone.core.fields.StringField\n",
      "    subset_name:       fiftyone.core.fields.StringField\n",
      "    segmentations:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    coco_id:           fiftyone.core.fields.IntField\n",
      "    default_embedding: fiftyone.core.fields.VectorField\n",
      "16 [0.         0.         0.06283244 ... 0.         0.         0.        ]\n",
      "3 [0.         0.         0.         ... 0.01344483 0.         0.10111439]\n",
      "2 [0.05323912 0.03975559 0.09020232 ... 0.         0.         0.        ]\n",
      "1 [0.02322646 0.         0.01290595 ... 0.00014826 0.07295725 0.        ]\n"
     ]
    }
   ],
   "source": [
    "combined_dataset.reload()\n",
    "print(combined_dataset)\n",
    "\n",
    "sample = combined_dataset.first()\n",
    "for detection in sample[\"segmentations\"].detections:\n",
    "    print(detection.label, detection.patches_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078e191c",
   "metadata": {},
   "source": [
    "### üóÑÔ∏è Exporting the Combined ARCADE Dataset and Publishing to Hugging Face ü§ó\n",
    "\n",
    "This final step packages the merged ARCADE dataset into a shareable format and uploads it to the Hugging Face Hub.\n",
    "\n",
    "#### üöö Step 1: Clone the Dataset\n",
    "We create a **clone** of the `arcade_combined` dataset to keep the export operation clean and isolated. This cloned dataset is named `arcade_combined_export`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "999433db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the dataset\n",
    "cloned_dataset = combined_dataset.clone(name=\"arcade_combined_fiftyone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee64010",
   "metadata": {},
   "source": [
    "#### üíæ Step 2: Export to Local Directory\n",
    "Using `FiftyOneDataset` format, the cloned dataset is exported to a directory (`./arcade_combined_fiftyone`). This includes:\n",
    "- Image files\n",
    "- COCO-style annotations (in this case, from the `\"segmentations\"` field)\n",
    "- Dataset metadata\n",
    "\n",
    "The `overwrite=True` flag ensures any existing content in the folder is safely replaced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8b11d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting samples...\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [1.3s elapsed, 0s remaining, 2.3K docs/s]         \n"
     ]
    }
   ],
   "source": [
    "# Set export directory\n",
    "export_dir = \"./arcade_combined_fiftyone\"\n",
    "\n",
    "# Export in FiftyOne format\n",
    "cloned_dataset.export(\n",
    "    export_dir=export_dir,\n",
    "    dataset_type=fo.types.FiftyOneDataset,\n",
    "    label_field=\"segmentations\",  # or other label field you want to export\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a72e57c",
   "metadata": {},
   "source": [
    "#### ü§ó Step 3: Push to Hugging Face Hub\n",
    "With just one line of code, we use `push_to_hub()` to upload the dataset directly to the Hugging Face Hub. The dataset will appear under the user or organization space defined by the credentials used.\n",
    "\n",
    "Publishing to Hugging Face allows others to:\n",
    "- **Easily reuse your dataset** in notebooks, apps, or models\n",
    "- **View it through the FiftyOne Web App integration**\n",
    "- **Promote reproducibility and collaboration** in open-source healthcare AI research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deee2d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/var/folders/6y/g2mslh_s7fz7qtj9vrxntqtm0000gn/T/tmpwjqsg_uf' already exists; export will be merged with existing files\n",
      "Exporting samples...\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [1.1s elapsed, 0s remaining, 2.9K docs/s]         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading media files in 2 batches of size 3000:   0%|          | 0/2 [00:00<?, ?it/s]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
      "Uploading media files in 2 batches of size 3000:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [02:37<02:37, 157.61s/it]No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "Uploading media files in 2 batches of size 3000: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [02:37<00:00, 78.88s/it] \n"
     ]
    }
   ],
   "source": [
    "from fiftyone.utils.huggingface import push_to_hub\n",
    "\n",
    "push_to_hub(cloned_dataset, \"arcade_fiftyone\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fo_healthcare_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
