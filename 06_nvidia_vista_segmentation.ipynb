{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cedd252",
   "metadata": {},
   "source": [
    "# ðŸ¥ Visual AI in Healthcare with FiftyOne - 3D CT Segmentation with NVIDIA VISTA and FiftyOne\n",
    "**Empowering medical imaging workflows with open-source tools and modern AI**\n",
    "\n",
    "This notebook is part of the **â€œVisual AI in Healthcare with FiftyOneâ€** series. In this module, we explore how to integrate NVIDIAâ€™s powerful foundation model **VISTA-3D** with **FiftyOne** to visualize, manage, and analyze segmentation results on volumetric CT scan data.\n",
    "\n",
    "ðŸ’¡ **What youâ€™ll learn in this notebook:**\n",
    "\n",
    "- How to **load and visualize 3D CT scans** using open-source tools like NiBabel and FiftyOne  \n",
    "- How to **convert DICOM/NRRD volumes into video samples** for better inspection in FiftyOne  \n",
    "- How to **enrich CT scan samples with patient and scan metadata**  \n",
    "- How to **run NVIDIA VISTA-3D** foundation model via API on medical images  \n",
    "- How to **parse and visualize segmentation masks** returned from the model on each frame  \n",
    "- How to **explore segmentations interactively** with FiftyOne App\n",
    "\n",
    "ðŸ“¦ **Dataset**: We use the `dgural/Total-Segmentator-50` dataset hosted on Hugging Face, which includes 50 CT scans and associated metadata.\n",
    "\n",
    "ðŸ”¬ **Model**: NVIDIA VISTA-3D foundation model for slice-level segmentation.\n",
    "\n",
    "ðŸ“š **Part of the notebook series:**\n",
    "1. `01_load_arcade_dataset.ipynb` â€“ Load and visualize the ARCADE dataset.  \n",
    "2. `02_load_deeplesion_balanced.ipynb` â€“ Curate and balance the DeepLesion dataset.  \n",
    "3. `03_vlms_analysis_arcade.ipynb` â€“ Use VFMs like NVLabs_CRADIOV3 in dataset undersatnding for ARCADE. \n",
    "4. `04_finetune_yolo8_stenosis.ipynb` â€“ Train and integrate YOLOv8 for stenosis detection.  \n",
    "5. `05_medsam2_ct_scan.ipynb` â€“ Run MedSAM2 on CT scans for segmentation.  \n",
    "6. `06_nvidia_vista_segmentation.ipynb` â€“ Explore NVIDIA-VISTA-3D.  \n",
    "7. `07_medgemma_vqa.ipynb` â€“ Perform visual question answering and classification with MedGemma.\n",
    "\n",
    "All notebooks are standalone but are best experienced sequentially.\n",
    "\n",
    "> Run this notebook in an environment with ffmpeg, pynrrd, NiBabel, FiftyOne, and API access to NVIDIA VISTA-3D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1617b3c",
   "metadata": {},
   "source": [
    "### âœ… Requirements\n",
    "\n",
    "Please install all the requeriments for running this notebook\n",
    "\n",
    "```\n",
    "pip install pynrrd nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1a005d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.utils.huggingface as fouh\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import requests\n",
    "import tempfile\n",
    "import zipfile\n",
    "import io\n",
    "import shutil\n",
    "import nrrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TotalSegmentator dataset from Hugging Face\n",
    "dataset = fouh.load_from_hub(\"dgural/Total-Segmentator-50\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44eea36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    }
   ],
   "source": [
    "session = fo.launch_app(dataset, port=5151, auto=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f906afa",
   "metadata": {},
   "source": [
    "Download the CT Scans - https://github.com/danielgural/totalsegmentator.git\n",
    "\n",
    "Follow this notebook: https://voxel51.com/blog/segment-anything-in-a-ct-scan-with-nvidia-vista-3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "202c511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ct(scan_name):\n",
    "    ct_filepath = \"TotalSegmentator/\" + scan_name + \"/ct.nii.gz\"\n",
    "    dir_name = scan_name + \"_video\"\n",
    "    new_dir_path = os.path.join(os.path.dirname(ct_filepath), dir_name)\n",
    "    os.makedirs(new_dir_path, exist_ok=True)\n",
    "\n",
    "    scan = nib.load(ct_filepath).get_fdata()\n",
    "    for plane in range(scan.shape[2]):\n",
    "        p = scan[:,:,plane].astype(np.uint8)\n",
    "        img = Image.fromarray(p)\n",
    "        img.save(f'{new_dir_path}/plane{plane}.png')\n",
    "\n",
    "    mov_in = os.path.join(f'{new_dir_path}/plane%d.png')\n",
    "    mov_out = os.path.join(f'{new_dir_path}/{scan_name}.mp4')\n",
    "    !ffmpeg -i {mov_in} -vcodec libx264 -vf \"pad=ceil(iw/2)*2:ceil(ih/2)*2\" -r 24 -y -an {mov_out}\n",
    "\n",
    "    sample = fo.Sample(filepath=mov_out)\n",
    "    sample[\"ct_filepath\"] = os.path.abspath(ct_filepath)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d43452",
   "metadata": {},
   "outputs": [],
   "source": [
    "scans = os.listdir(\"TotalSegmentator\")\n",
    "scans.sort()\n",
    "df = pd.read_csv(\"TotalSegmentator/meta.csv\", sep=';')\n",
    "\n",
    "dataset = fo.Dataset(name=\"TotalSegmentator\", overwrite=True)\n",
    "\n",
    "samples = []\n",
    "for i, scan in enumerate(scans):\n",
    "    if i == 51:\n",
    "        break\n",
    "    if scan.find(\".csv\") == -1:\n",
    "        sample = load_ct(scan)\n",
    "        row = df[df['image_id'] == scan]\n",
    "        sample[\"image_id\"] = row[\"image_id\"].item()\n",
    "        sample[\"age\"] = row[\"age\"].item()\n",
    "        sample[\"gender\"] = row[\"gender\"].item()\n",
    "        sample[\"institute\"] = row[\"institute\"].item()\n",
    "        sample[\"study_type\"] = row[\"study_type\"].item()\n",
    "        sample[\"split\"] = row[\"split\"].item()\n",
    "        sample[\"manufacturer\"] = row[\"manufacturer\"].item()\n",
    "        sample[\"scanner_model\"] = row[\"scanner_model\"].item()\n",
    "        sample[\"kvp\"] = row[\"kvp\"].item()\n",
    "        sample[\"pathology\"] = row[\"pathology\"].item()\n",
    "        sample[\"pathology_location\"] = row[\"pathology_location\"].item()\n",
    "        samples.append(sample)\n",
    "\n",
    "dataset.add_samples(samples)\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e6828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_url = \"https://health.api.nvidia.com/v1/medicalimaging/nvidia/vista-3d\"\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer {Your NVIDIA API KEY}\",\n",
    "}\n",
    "\n",
    "for sample in dataset:\n",
    "    payload = {\n",
    "        \"prompts\": {\"classes\": None, \"points\": None},\n",
    "        \"image\": f\"https://github.com/danielgural/totalsegmentator/raw/main/{sample.image_id}.ct.nii.gz\"\n",
    "    }\n",
    "\n",
    "    session_req = requests.Session()\n",
    "    response = session_req.post(invoke_url, headers=headers, json=payload)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    try:\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            z = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "            z.extractall(temp_dir)\n",
    "            output_path = f\"TotalSegmentator/{sample.image_id}/{sample.image_id}.nrrd\"\n",
    "            shutil.move(os.path.join(temp_dir, os.listdir(temp_dir)[0]), output_path)\n",
    "    except Exception as e:\n",
    "        with open(f\"TotalSegmentator/{sample.image_id}/{sample.image_id}.nrrd\", 'w') as file:\n",
    "            file.write(response.text)\n",
    "\n",
    "    data, header = nrrd.read(f'TotalSegmentator/{sample.image_id}/{sample.image_id}.nrrd')\n",
    "    for frame_no, frame in sample.frames.items():\n",
    "        mask = data[:,:,frame_no-1]\n",
    "        frame[\"seg_mask\"] = fo.Segmentation(mask=mask)\n",
    "    sample.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "health_care",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
